"""A module used to sample using Metropolis-Hastings algorithm.

TO DO: longer description?

Attributes
----------
State : TypeVar
    A generic type of state, can be int, List[int], np.array, ...

Classes
-------
Metropolis
MetropolisHastings
"""

from typing import Sequence, Callable, Any
from nptyping import NDArray, Shape
from markov_chain import MarkovChain, State
from utils import matrix_to_next, matrix_to_trans, trans_to_next
import numpy as np


def metropolis_hastings_classic_step(next_candidate: Callable[[State], State],
                                     stationary: NDArray[Shape['*'], Any],
                                     candidate_transition: Callable[[State, State], float]
                                     ) -> State:
    def next_step(current: State) -> State:
        Z = next_candidate(current)
        V = np.random.uniform()
        if V <= min(1,
                    stationary[Z]
                    * candidate_transition(current, Z)
                    / stationary[current]
                    / candidate_transition(Z, current)
                    ):
            return Z
        else:
            return current

    return next_step

class Metropolis(MarkovChain):
    """A class used to represent a markov chain generated by Metro algorithm.

    TO DO: longer description?

    Attributes
    ----------
    _current: State
        Current state of the markov chain.
     next_state: Callable[[State, Optional[Sequence[State]]], State]
            Function of current state (and optionally past) that returns next
            state:
            (current: State, past: Sequence[State] = None) -> State
    _next_candidate: Callable[[State], State]
        Function of current state that returns next candidate:
        (current: State) -> State
    _stationary: NDArray[Shape['*'], Any]
        Target stationary distribution.
    _past_max_len: int, default=0
        Maximal length of the past sequence that one wants to track.
        If equal to 0, then no past is tracked.
    _past: Sequence[State], optional
        Sequence of past states.

    Methods
    -------
    sample(n: int) -> Sequence[State]:
        Get sample of length n of the markov chain.
    move(n_steps: int) -> State
        Move the markov chain by n steps.
    """

    def __init__(self,
                 current: State,
                 next_candidate: NDArray[Shape['*, *'], Any]
                 | Callable[[State], State],
                 stationary: NDArray[Shape['*'], Any],
                 past_max_len: int = 0,
                 past: Sequence[State] = None
                 ) -> None:
        """Initialize Metropolis class.

        Parameters
        ----------
        current: State
            Current state of the markov chain.
        next_candidate: NDArray[Shape['*, *'], Any] | Callable[[State], State]
            Function of current state or matrix that returns next candidate:
            (current: State) -> State
        stationary: NDArray[Shape['*'], Any]
            Target stationary distribution.
        past_max_len: int, optional
            Maximal length of the past sequence that one wants to track.
            If equal to 0, then no past is tracked.
        past: Sequence[State], optional
            Sequence of past states.
        """
        self._stationary = stationary
        self._next_candidate = matrix_to_next(next_candidate)

        def next_state(current_: State) -> State:
            Z = self._next_candidate(current_)
            V = np.random.uniform()
            if V <= min(1, stationary[Z] / stationary[current_]):
                return Z
            else:
                return current_

        super().__init__(current=current,
                         next_state=next_state,
                         past_max_len=past_max_len,
                         past=past)

    @property
    def stationary(self) -> NDArray[Shape['*'], Any]:
        """Get the stationary distribution of the markov chain."""
        return self._stationary

    @stationary.setter
    def stationary(self, stationary: NDArray[Shape['*'], Any]) -> None:
        """Set the stationary distribution of the markov chain."""
        if sum(stationary) == 1:
            self._stationary = stationary
        else:
            raise ValueError("Stationary distribution does not sum to 1.")

    @property
    def next_candidate(self) -> Callable[[State], State]:
        """Get the next_candidate function or matrix of the markov chain."""
        return self._next_candidate


class MetropolisHastings(MarkovChain):
    """A class used to represent a markov chain generated by M-H algorithm.

    TO DO: longer description?

    Attributes
    ----------
    _current: State
        Current state of the markov chain.
    _num_states: int
        Number of states.
     next_state: Callable[[State, Optional[Sequence[State]]], State]
            Function of current state (and optionally past) that returns next
            state:
            (current: State, past: Sequence[State] = None) -> State
    _next_candidate: Callable[[State], State]
        Function of current state that returns next candidate:
        (current: State) -> State
    _candidate_transition: Callable[[State, State], float]
        Function of 2 states that returns probabilities of transitions
        between them:
        (state_1: State, state_2: State) -> [0,1]
    _stationary: NDArray[Shape['*'], Any]
        Target stationary distribution.
    _past_max_len: int, default=0
        Maximal length of the past sequence that one wants to track.
        If equal to 0, then no past is tracked.
    _past: Sequence[State], optional
        Sequence of past states.

    Methods
    -------
    sample(n: int) -> Sequence[State]:
        Get sample of length n of the markov chain.
    move(n_steps: int) -> State
        Move the markov chain by n steps.
    """

    def __init__(self,
                 current: State,
                 num_states: int,
                 candidate_transition: NDArray[Shape['*, *'], Any]
                 | Callable[[State, State], float],
                 stationary: NDArray[Shape['*'], Any],
                 past_max_len: int = 0,
                 past: Sequence[State] = None
                 ) -> None:
        """Initialize Metropolis class.

        Parameters
        ----------
        current: State
            Current state of the markov chain.
        num_states: int
            Number of states.
        candidate_transition: NDArray[Shape['*, *'], Any]
                            | Callable[[State, State], float]
            Function or matrix of  probabilities of between transitions:
            (state_1: State, state_2: State) -> [0,1]
        stationary: NDArray[Shape['*'], Any]
            Target stationary distribution.
        past_max_len: int, optional
            Maximal length of the past sequence that one wants to track.
            If equal to 0, then no past is tracked.
        past: Sequence[State], optional
            Sequence of past states.
        """
        self._num_states = num_states
        self._stationary = stationary
        self._candidate_transition = matrix_to_trans(candidate_transition)
        self._next_candidate = trans_to_next(candidate_transition, num_states)

        def next_state(current_: State) -> State:
            Z = self._next_candidate(current_)
            V = np.random.uniform()
            if V <= min(1,
                        stationary[Z]
                        * self._candidate_transition(current_, Z)
                        / stationary[current_]
                        / self._candidate_transition(Z, current_)
                        ):
                return Z
            else:
                return current_

        super().__init__(current=current,
                         next_state=next_state,
                         past_max_len=past_max_len,
                         past=past)

    @property
    def stationary(self) -> NDArray[Shape['*'], Any]:
        """Get the stationary distribution of the markov chain."""
        return self._stationary

    @stationary.setter
    def stationary(self, stationary: NDArray[Shape['*'], Any]) -> None:
        """Set the stationary distribution of the markov chain."""
        if sum(stationary) == 1:
            self._stationary = stationary
        else:
            raise ValueError("Stationary distribution does not sum to 1.")

    @property
    def candidate_transition(self) -> Callable[[State, State], float]:
        """Get the candidate transition probabilities function."""
        return self._candidate_transition


if __name__ == "__main__":
    n = 5
    # metro = Metropolis(current=0,
    #                    next_candidate=np.ones((n, n))/n,
    #                    stationary=[0.1, 0.1, 0.5, 0.1, 0.2])
    #
    # x = metro.sample(1000)
    from utils import random_stochastic_matrix
    metro = MetropolisHastings(current=0,
                               candidate_transition=random_stochastic_matrix(n),
                               num_states=n,
                               stationary=[0.35, 0.1, 0.1, 0.1, 0.35])

    x = metro.sample(1000)

    import matplotlib.pyplot as plt
    plt.hist(x, density=True, ec='black', bins=np.arange(n+1))
    plt.show()

