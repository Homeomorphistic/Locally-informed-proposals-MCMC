In the previous section we have seen that a deterministic approach of computing salesman tours is infeasible, so we can turn now to probabilistic methods of MCMC. 

\subsection{Basic idea}
	Instead of checking all possible tours, now we want sample from this space, so the question is, how do we define a distribution there? It is usually done with a \textit{softmax}, a transformation of our target function, which is in this case a distance of a tour.
	\begin{definition}
		For a given vector $\x = (x_1, x_2, \ldots, x_d)^T \in \R^d$ a softmax function $s: \R^d \rightarrow \left[0, 1\right]^d$ is defined as
		\begin{align*}
			&s(\x)_i = \frac{e^{x_i}}{\sum_{j=1}^{d} e^{x_j}}, \\
			&s(\x) = \left( s(\x)_1, s(\x)_2, \ldots, s(\x)_d \right).
		\end{align*}
	\end{definition}
	Such defined function is a probability distribution and it does not change the order of a given vector. This is important for us, because we can apply a softmax to the distances (weights) of the tours, so that we change them into distribution, but we will not change the relation between tours -- ones with longer distances will have greater probability. As we are interested in shortest distances, we can add a minus sign to give them the greatest probability.
	
	It is still not clear, how does it help with the traveling salesman problem -- even with fast sampling algorithm. Why are we interested in probabilities instead of weights? It is, because when looking for a maximum of softmax of a vector, we find a maximum of original vector, so in case of our problem:
	\begin{equation*}
		\sigma_{\min} = \underset{\sigma \in S_n}{\argmin} \left( w_{\sigma} \right) = \underset{\sigma \in S_n}{\argmax} \frac{e^{-w_{\sigma}}}{\sum_{\sigma' \in S_n} e^{-w_{\sigma'}}},
	\end{equation*}
	where $w_{\sigma}$ is distance (weight) of a tour (permutation) $\sigma$. When $\sigma_{\min}$ is maximizing probability it means when we sample from this distribution it will appear most often. This is the core of MCMC methods -- approximate solution with most probable state. 

\subsection{Metropolis-Hastings algorithm}
	Let us get back to the notation of weights and use a vector $\bfw = (w_1, w_2, \ldots, w_N)^T$ representing distances of all possible tours. As we noticed earlier, this space is enormous, so calculating softmax of this vector $s(\bfw)$ is again not feasible, because of enormous sum in the denominator $\sum_{j=1}^{N} e^{w_j}$. This is where Metropolis-Hastings algorithm comes in handy -- we do not need actually probabilities, we just need their quotients, and this is where the sums will erase each other. What we actually need is something proportional to the probability:
	\begin{equation*}
		\pi_i \propto e^{-w_i}.
	\end{equation*}
	
	
	
	Using softmax is even more beneficial, because of the properties of exponential function. In each step of M-H algorithm we need to compute:
	\begin{equation*}
		\frac{\pi_j \bfQ_{j,i}}{\pi_i \bfQ_{i,j}} = e^{-(w_j-w_i)} \cdot \frac{\bfQ_{j,i}}{\bfQ_{i,j}}.
	\end{equation*}
	If candidate matrix $\bfQ$ is symmetric this equation simplifies further. In practice we will be using logarithms of quotients in M-H algorithm, because multiplying numbers from $(0,1)$ get small quickly, so that they get out of the range of computer abilities. After applying logarithm we have:
	\begin{equation*}
		\log \left( \frac{\pi_j \bfQ_{j,i}}{\pi_i \bfQ_{i,j}} \right) = -(w_j-w_i) + \log(\bfQ_{j,i}) - \log(\bfQ_{i,j}).
	\end{equation*}
	Again, if candidate matrix $\bfQ$ is symmetric we are left only with evaluating $w_j-w_i$ which is simple and it does not involve computing any other weights.
	
	Now that we have a target distribution we can try sampling using a MC produced by M-H algorithm and after some point we should reach the tour with highest probability, \ie smallest distance covered. To do that we need to define candidate matrix $\bfQ$. The better the candidates, the faster MC can get to the minimum.

\subsection{Candidates}
	Let us start with considering what the candidate is. We know that the space of all possible tours is enormous, so we cannot take every tour into consideration. Instead we focus on what we will call from now on \textit{neighbours}.
	\begin{definition}
		A neighbour $\sigma'$ of a permutation $\sigma$ is a permutation, that for some $k, l$ it satisfies $\sigma'(k) = \sigma(l)$, $\sigma'(l) = \sigma(k)$ and $\sigma'(i) = \sigma(i)$ for the rest of indices.
	\end{definition}
	These neighbours are the original tour with two swaped indices. This let  us consider a smaller space -- there are $\binom{n}{2} = \frac{n(n-1)}{2} \approx n^2$ neighbours if the number of vertices is $n$.

\subsection{Random neighbours (RN)}
	One approach is to sample neighbours uniformly, it has a benefit of being simple to understand and implement. Random neighbours (abbrv. RN) method was already been successfully presented in \cite{decryption_tsp_MCMC}. Sampling them uniformly is equivalent to choosing random indices to swap, so it can be done efficiently. This way we do not need to create a candidate matrix, we just use a simple procedure. Most of the entries in this matrix would be $0$, because we choose only some subset of all possible permutations to be our neighbours. It is a symmetrical procedure (every neighbour has the same probability), so the step in M-H algorithm simplifies further.
	
	\subsubsection{Computational considerations}
		For this algorithm to be truly efficient, we need to find some other way to calculate distance (weight) of a tour, as it can also contain many edges. Without any optimizations for each tour $\sigma$ we need to calculate its distance (weight):
		\begin{equation*}
			w_\sigma = \sum_{i=1}^{n-1} w_{\sigma(i), \sigma(i+1)} + w_{\sigma(n), \sigma(1)}.
		\end{equation*}
		
		What was observed in \cite{decryption_tsp_MCMC} is that the weight does not change drastically when changing a tour to its neighbour. It is because most of the edges stay the same. When given a tour $\sigma$ and its neighbour $\sigma'$ they differ only on those edges where swap is happening, let's say $k,l$. So for this situation we have tours:
		\begin{align*}
			\sigma = (\sigma(1), \ldots, \sigma(k-1), \sigma(k), \sigma(k+1), \ldots, \sigma(l-1), \sigma(l), \sigma(l+1), \ldots) \\
			\sigma' = (\sigma(1), \ldots, \sigma(k-1), \sigma(l), \sigma(k+1), \ldots, \sigma(l-1), \sigma(k), \sigma(l+1), \ldots)
		\end{align*}
		Assuming that we know the sum of weights for tour $\sigma$ to obtain the new one for neighbour $\sigma'$ we need to remove from it weights $w_{\sigma(k-1), \sigma(k)}$, $w_{\sigma(k), \sigma(k+1)}$, $w_{\sigma(l-1), \sigma(l)}$, $w_{\sigma(l), \sigma(l+1)}$ and add $w_{\sigma(k-1), \sigma(l)}, w_{\sigma(l), \sigma(k+1)}, w_{\sigma(l-1), \sigma(k)}, w_{\sigma(k), \sigma(l+1)}$. This is only $8$ operations per neighbour, a constant complexity cost (if we can get instantly weights).
		
	\subsubsection{Implementation}
		To sum up all the information we summarize it in Algorithm (\ref{alg:rnd_neigh}). As mentioned before, we will be working on logarithms, because they are better suited for computer computations.
		
		\input{algs/rnd_neigh}
		
	\subsubsection{Complexity}
		As mentioned before this algorithm is simple because of uniform distribution. It requires 2 samplings, which in practice both are the same (random sampling) and 8 operations of adding and subtracting which in theory could be instant, but in reality are of linear complexity, because of searching of weights through the list.
		
		Space complexity is constant -- we need only two variables to contain current weight and state. In practice we also use a memory for storing weights of the problem.
		\clearpage
		
\subsection{Locally-informed proposals (LIP)}
	Locally-informed proposals (abbrv. LIP) are more complicated family of methods, they include more computational labor. The approach with uniform distribution of candidates is less complex, but forces us to make a lot of iterations. It is because choosing neighbours randomly conveys no information, so it is required for us to check a lot of neighbours until we find a better one. This idea was mentioned in \cite{maddison2021oops} and we will try to apply it efficiently.
	
	This time, we want to compute a \textit{local} distribution of neighbours and sample them from it. This is why the method is called \textit{locally-informed proposals} (abbrv. LIP) -- we compute a local proposal. It has to be done efficiently too, because number of neighbours grows quadratically with the number of vertices (so for \textit{dsj1000} its 1 million neighbours).
	
	\subsubsection{Theoretical background}
		The idea is to balance the increase in the probability of neighbour with decrease of reverse probability, such that it will be easy to compute. One way is to use locally-informed proposals, which will be proportional to the same quotient of target distribution as in M-H step, so:
		\begin{equation*}
			\bfQ_{i,j} \propto e^\frac{-(w_{j} - w_i)}{\tau}.
		\end{equation*}
		Here $\tau>0$ is temperature parameter. The distribution is chosen in such a way, so that we can easily group up the terms in acceptance criterion:
		\begin{equation*}
			\frac{\pi_j \bfQ_{j,i}}{\pi_i \bfQ_{i,j}} = e^{-(w_j-w_i)} \cdot \frac{e^\frac{-(w_{i} - w_j)}{\tau}}{e^\frac{-(w_{j} - w_i)}{\tau}} \cdot \frac{C_j}{C_i} = e^{\left( -(w_j-w_i) \left(1 - \frac{2}{\tau}\right) \right)} \cdot \frac{C_j}{C_i},
		\end{equation*}
		where $C_i, C_j$ are normalizing constants. Setting $\tau=2$ terms in exponent cancel out, so we are left with normalizing constants. Again using logarithms is beneficial in computer science, so the acceptance criterion has form:
		\begin{equation*}
			\log\left(\frac{\pi_j \bfQ_{j,i}}{\pi_i \bfQ_{i,j}}\right) = \left( -(w_j-w_i) \left(1 - \frac{2}{\tau}\right) \right) + \log\left(C_j\right) - \log\left(C_i\right).
		\end{equation*}
		The temperature parameter that achieve balance is $\tau=2$ and was considered in \cite{zanella2020informed}.
	
	\subsubsection{Computational considerations}
		The observation here is similar to the previous one -- when we have differences in weights for all neighbours of a starting tour, we can update them and only some of them change in a significant way. Then we can calculate softmax on neighbour weights differences. One might notice now, that this procedure is not symmetrical, because softmax can be different when the sums dividing exponent of weights differences will be different. Most notably, when a neighbour will have a high transition probability, getting back will have lower probability, because it means that there is more distance. This means that we will be using M-H algorithm (not only Metropolis).
		
		Let us show this on an example: assume that we have chosen tour $\sigma$ and its neighbour $\sigma'$ that is connected with swapping indices $k$ and $l$. So for this situation we have tours:
		\begin{align*}
			\sigma = (\sigma(1), \ldots, \sigma(k-1), \sigma(k), \sigma(k+1), \ldots, \sigma(l-1), \sigma(l), \sigma(l+1), \ldots) \\
			\sigma' = (\sigma(1), \ldots, \sigma(k-1), \sigma(l), \sigma(k+1), \ldots, \sigma(l-1), \sigma(k), \sigma(l+1), \ldots)
		\end{align*}
		Now we need to think of a neighbour connected to some other swap for both of those tours, let's say $r$ and $s$. When $r$ and $s$ are far away from $k$ and $l$ we have almost the same tours, but with a swap on $k$ and $l$. So the neighbours $\sigma_{r,s}$, $\sigma'_{r,s}$ of $\sigma$ and $\sigma'$ respectively look like: 
		\begin{align*}
			\sigma_{r,s} = &(\ldots, \sigma(r-1), \sigma(s), \sigma(r+1), \ldots, \sigma(s-1), \sigma(r),\sigma(s+1), \ldots, \\
			&\ldots, \sigma(k-1), \sigma(k), \sigma(k+1), \ldots, \sigma(l-1), \sigma(l), \sigma(l+1), \ldots) \\
			\sigma'_{r,s} = &(\ldots, \sigma(r-1), \sigma(s), \sigma(r+1), \ldots, \sigma(s-1), \sigma(r), \sigma(s+1), \ldots, \\
			&\ldots \sigma(k-1), \sigma(l), \sigma(k+1), \ldots, \sigma(l-1), \sigma(k), \sigma(l+1), \ldots)
		\end{align*}
		This time we need differences in weights, so assuming we know it for neighbour $\sigma_{r,s}$ of $\sigma$, we can see that difference in weight of neighbour $\sigma'_{r,s}$ of $\sigma'$ is the same, because the weights changed only on $r$ and $s$ place, which are not connected to $k$ and $l$. This case covers most of the neighbours. 
		
		Let us think now about the case, when swap of $r$ and $s$ indices happen somewhere close to $k$ and $l$, for example $k = r-1$:
		\begin{align*}
			\sigma_{r,s} = &(\ldots, \sigma(k-1), \sigma(k), \sigma(s), \sigma(r+1), \ldots, \\
			&\ldots, \sigma(s-1), \sigma(r), \sigma(s+1), \ldots, \sigma(l-1), \sigma(l), \sigma(l+1), \ldots) \\
			\sigma'_{r,s} = &(\ldots, \sigma(k-1), \sigma(l), \sigma(s), \sigma(r+1), \ldots, \\
			& \ldots, \sigma(s-1), \sigma(r), \sigma(s+1), \ldots, \sigma(l-1), \sigma(k), \sigma(l+1), \ldots)
		\end{align*}
		This time the difference in weights $\sigma_{r,s}$ and $\sigma'_{r,s}$ cannot be the same, because there are different edges connected to $s$. That forces us to manually get weights corresponding to different edges and update the differences in weights. It means, that some neighbours (swaps) have to be considered separately. These are the scenarios when $r$ or $s$ are elements of $\left\{ (k-1), k, (k+1), (l-1), l, (l+1) \right\}$.
		
	\subsubsection{Example}
		To see this problem let us focus on some easier example and then generalize it to get an estimation of number of steps required to update weights.
		
		Let us set $k=2$ and $l=7$, then the set of indices to consider is $\left\{ 1,2,3,6,7,8 \right\}$ and the permutations:
		\begin{align*}
			\sigma &= (1, 2, 3, 4, 5, 6, 7, 8, 9, \ldots) \\
			\sigma' &= (1, 7, 3, 4, 5, 6, 2, 8, 9, \ldots).
		\end{align*}
		We can represent neighbours as a tuple of integers, which mean the indices to swap. The table \ref{tab:neighbours} represents neighbours. To not repeat elements, we can focus only on the upper triangle of a matrix of those tuples.
		
		\input{tables/neighbours}
		
		Light gray cells are neighbours with one index swapped close to considered set, and darker gray cells are neighbours with two indices swapped close to considered set. 
		
		Unfortunately there is no other way rather than compute manually weight difference for darker gray cells, because their edges close to $k=2$ and $l=7$ are completely different. These do not cause a lot of computation, because there are only $\binom{6}{2} = \frac{6 \cdot 5}{2}=15$ cases.
		
		We can say something more about light gray ones, where there is only one index close to the considered set. Let us set $r=3$ and $s=9$, which means that we are looking for weight differences of neighbours obtained by swapping $3$ and $9$. So the neighbours have form:
		\begin{align*}
			\sigma_{3,9} &= (1, 2, 9, 4, 5, 6, 7, 8, 3, \ldots) \\
			\sigma'_{3,9} &= (1, 7, 9, 4, 5, 6, 2, 8, 3, \ldots).
		\end{align*}
		
		Let us denote $d_{3,9} = w_{\sigma} - w_{\sigma_{3,9}}$ as a difference between current permutation and its neighbour connected to swap  $r=3$ and $s=9$. Similarly $d'_{3,9} = w_{\sigma'} - w_{\sigma'_{3,9}}$ is a difference between neighbour of current permutation and its neighbour. Assume we know vector of differences for $\sigma$ and its weight $w_\sigma$. Given that, we also know $w_{\sigma_{3,9}}$, because
		\begin{equation*}
			w_{\sigma_{3,9}} = w_\sigma + d_{3,9}.
		\end{equation*}
		Consider difference of weight differences here:
		\begin{equation*}
			d_{39} - d'_{3,9} = w_{\sigma} - w_{\sigma_{3,9}} - (w_{\sigma'} - w_{\sigma'_{3,9}}),
		\end{equation*}
		after rearranging we have:
		\begin{equation*}
			d'_{3,9} = d_{3,9} - (w_{\sigma} - w_{\sigma'}) + (w_{\sigma_{3,9}} - w_{\sigma'_{3,9}}).
		\end{equation*}
		We are interested in getting $d'_{3,9}$. The only term in this equation not known to us is $w_{\sigma_{3,9}} - w_{\sigma'_{3,9}}$ (we know $(w_{\sigma} - w_{\sigma'})$ because we know differences in weights of $\sigma$). It is easy to see when looking at $\sigma_{3,9}$ and $\sigma'_{3,9}$ that :
		\begin{equation*}
			w_{\sigma_{3,9}} - w_{\sigma'_{3,9}} = (w_{1,2} + w_{2,9} + w_{6,7} + w_{7,8}) - (w_{1,7} + w_{7,9} + w_{6,2} + w_{2,8}).
		\end{equation*}
		We can generalize that equation for any $p \notin \left\{ 1,2,3,6,7,8 \right\}$:
		\begin{equation*}
			w_{\sigma_{3,p}} - w_{\sigma'_{3,p}} = f_3(p) = C + w_{2,p} - w_{7,p}.
		\end{equation*}
		This difference is some function of $p$, changing this index will not change values of any other weights. So we can have a general formula for any $r \in \left\{ 1,2,3,6,7,8 \right\}$ and $s \notin \left\{ 1,2,3,6,7,8 \right\}$. Constant $C$ and indices $2,7$ will change depending on $k,l$ and their relative position to $r$.
		
		Now we know, that for a given row from $\left\{ 1,2,3,6,7,8 \right\}$ we can compute the difference $d'_{3,9}$. We can do it efficiently using vector operations -- we need one vector subtraction and one computation of constant $C$. In reality vector subtraction is just subtracting each number for each other, so for each $r \in \left\{ 1,2,3,6,7,8 \right\}$ we have at most $n$ (number of vertices) operations and we have $6$ distinct choices of $r$, so $6\cdot n$ operations.
	
	\subsubsection{Implementation}
	
		To sum up all the information we summarize it in Algorithm (\ref{alg:loc_neigh}). As mentioned before, we will be working on logarithms, because they are better suited for computer computations.

		The core of this algorithm is still the same, but we need to add more complicated part with computing neighbour weights differences and updating them after each step of a main loop.
		
		Unfortunately, there are more practical things to consider this time. In this algorithm we are actually calculating softmax function, nothing is vanishing here. Computing exponents of large numbers ends up with $\infty$ or $-\infty$ on a computer. Also, for datasets like \textit{dsj1000} there are around 1 million neighbours, and we need to keep probabilities with higher precision, that is a lot of memory to use.
		
		Working on differences can alleviate this problem (for some cases). Let's say we know weight of our current tour $w_\sigma$ and its neighbours weights vector $\bfw_\sigma$. We can think of every weight in this vector as a difference between it and current tour weight: $\bfd_{\sigma}[i] = w_\sigma + d_i$. By $\bfd_\sigma[(i,j)]$ we mean the index of a swap $i,j$ (it needs to be found).
		
		\input{algs/loc_neigh}
		
	\subsubsection{Complexity}
		This algorithm is more complicated and it significantly lowers the performance. This time for each step of M-H algorithm we need to compute softmax to get probabilities, which is already a hard task, because of computing exponents. Besides that we need to sample from (sometimes) long vector. There is also a sub-procedure with two loops.
		
		The function \textit{get\_difference} is not implemented as in example, because we wanted to avoid working with large matrices and so avoid problems with memory. In practice one would need to keep matrix of weights, which would be of size $n \times n$ and the same for differences. More than a half of its elements would be empty (zeros) so we would waste a lot of memory and also do many unnecessary operations when adding or subtracting vectors from those matrices. Not using large matrices was also our goal when choosing MCMC methods for this problem.
		
		Space complexity is  also constant, but a lot bigger than previously, because we need to keep two  long vectors of probabilities (or weight differences).
	
\subsection{Simulated annealing}
	There is one important parameter that can be used both with random neighbours and locally-informed proposals and is associated with cooling. It has its roots within physics and is connected to energetic states of particles and Boltzmann distribution. The idea is to describe a probability of state using a cooling parameter $t_k$ (different than $\tau$ in LIP) such that it reminds the cooling of a metal and may change with each step:
	\begin{equation*}
		\pi_i = \frac{e^{\frac{-E_i}{t_k}}}{C},
	\end{equation*}
	where $C$ is normalizing constant.The quotient of probabilities then is:
	\begin{equation*}
		\frac{\pi_j}{\pi_i} = e^{\frac{E_i - E_j}{t_k}}
	\end{equation*}
	Setting this parameter high constitutes to all of the states being equally likely and with low value of parameter we have probability concentrated in the state with minimal energy.
	
	Using $t_k$ as a function of step in acceptance criterion will give us a non-homogeneous MC. Setting it to a constant value will produce a homogeneous MC.