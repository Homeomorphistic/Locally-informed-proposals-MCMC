\documentclass[a4paper, 12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage[polish]{babel}
\usepackage[top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{subcaption}
\usepackage{float}

\usepackage{listings}
\lstset{breaklines=true, numbers=left, stepnumber=2, language=Python}

\numberwithin{equation}{subsection}
\counterwithin{table}{subsection}
\counterwithin{figure}{subsection}

\begin{document}
	\thispagestyle{empty}
	\begin{center}
		\textbf{\large Uniwersytet Wroc\l{}awski\\
			Wydzia\l{} Matematyki i Informatyki\\
			Instytut Matematyczny}\\
		\textit{\large specjalno\'{s}\'{c}: Analiza danych}\\
		\vspace{4cm}
		\textbf{\textit{\large Bartosz Chmiela}\\
			\vspace{0.5cm}
			{\Large Locally-informed proposals in Metropolis-Hastings algorithm with applications}}\\
	\end{center}
	\vspace{3cm}
	{\large \hspace*{6.5cm}Praca magisterska\\
		\hspace*{6.5cm}napisana pod kierunkiem\\
		\hspace*{6.5cm}dr hab. Paw\l{}a Lorka }\\
	\vfill
	\begin{center}
		{\large Wroc\l{}aw 2022}\\
	\end{center}
	
	\newpage
	\begin{abstract}
		Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean placerat consequat ex, at rutrum sem tincidunt sit amet. Nullam leo felis, venenatis ac dui eu, tristique placerat lectus. Suspendisse tristique eu tortor ac eleifend. Proin nec velit rutrum, lobortis mi at, lobortis felis. Aenean viverra non velit vitae posuere. Aliquam ac ornare ligula. Nam scelerisque sit amet velit vitae molestie. Curabitur purus ligula, blandit ut sapien eu, placerat interdum metus. Morbi eu ultricies urna. Quisque nec nulla lorem. Sed maximus nunc nisl, sit amet porta velit ornare eget. Aliquam arcu metus, convallis quis felis et, aliquet pretium sapien. Mauris elementum turpis libero, sed aliquam nisi eleifend in. Suspendisse tempus, erat pharetra pretium pellentesque, mi ligula porttitor erat, et vestibulum ipsum augue et risus. Vivamus dictum rhoncus turpis eu pretium. Integer metus nisl, iaculis sit amet augue ut, egestas lobortis lacus.
		
		\rule{0.8\textwidth}{0.4pt}
		
		
		Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean placerat consequat ex, at rutrum sem tincidunt sit amet. Nullam leo felis, venenatis ac dui eu, tristique placerat lectus. Suspendisse tristique eu tortor ac eleifend. Proin nec velit rutrum, lobortis mi at, lobortis felis. Aenean viverra non velit vitae posuere. Aliquam ac ornare ligula. Nam scelerisque sit amet velit vitae molestie. Curabitur purus ligula, blandit ut sapien eu, placerat interdum metus. Morbi eu ultricies urna. Quisque nec nulla lorem. Sed maximus nunc nisl, sit amet porta velit ornare eget. Aliquam arcu metus, convallis quis felis et, aliquet pretium sapien. Mauris elementum turpis libero, sed aliquam nisi eleifend in. Suspendisse tempus, erat pharetra pretium pellentesque, mi ligula porttitor erat, et vestibulum ipsum augue et risus. Vivamus dictum rhoncus turpis eu pretium. Integer metus nisl, iaculis sit amet augue ut, egestas lobortis lacus.
	\end{abstract}
	\clearpage
	
	\tableofcontents
	\listoftables
	\listoffigures
	\clearpage
	
	\section{Introduction}
		The Markov Chain Monte Carlo methods (abbrv. MCMC) are a family of algorithms used for sampling from a given probability distribution. At first they do not seem useful for solving practical deterministic problems, but with some tweaks they can become a powerful tool. It happens especially when space of possible solutions is enormous and computing becomes infeasible for machines. These offer a shortcut for obtaining ``close enough'' answers.
		
		At their core, MCMC methods generate a Markov Chain (abbrv. MC) with a defined distribution and sample using it. The convergence of the chain is assured by ergodic theorems. The most known of them is \textit{Metropolis-Hastings} algorithm, which constructs a MC using another set of distributions, maybe simpler ones.
		
		In this thesis we work on \textit{locally-informed proposals}, which involve determining \textit{local} distribution -- which comes down to finding transition probabilities of the state. They are a bit more complex and computationally heavy, but offer better results with less iterations. 
		
		To test this method we will need a deterministic problem which quickly becomes infeasible for machines to compute -- one of them is a well-known traveling salesman problem. The testing is carried out using its benchmark training set \textit{tsplib95} and implemen-tation is provided in \textit{Python3}.
	
	\section{Markov Chains}
	
	\section{Markov Chain Monte Carlo methods}
	
	\section{Traveling salesman problem}
	
	\section{Decoding encrypted text}
	
	\section{Code description?}
	
	\section{Conclusions}
	
	\clearpage
	\addcontentsline{toc}{section}{References}
	\nocite{*}
	\bibliographystyle{abbrv}
	\bibliography{references}
	
	
	
	\appendix
	\clearpage
	\section{Source code} \label{apsec:code}
		%\lstinputlisting[firstline=13, lastline=192]{genomeTesting.R}
	\clearpage
	
	
\end{document}